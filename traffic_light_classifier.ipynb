{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6564c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b3a5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network():\n",
    "    \"\"\"\n",
    "    Define the network\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "784eba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(file_path, model):\n",
    "\n",
    "    x_,y_ = pickle.load( open(file_path, \"rb\" ) )\n",
    "    random_state = 130\n",
    "    X_train, x_validation, y_train, y_validation = train_test_split(x_, y_, train_size = 0.80,\n",
    "                                                                    test_size = 0.2,\n",
    "                                                                    random_state = random_state)\n",
    "    # preprocess data\n",
    "    X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "    model.summary()\n",
    "    model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "    history = model.fit(X_normalized, y_one_hot, epochs=20, validation_split=0.2)\n",
    "\n",
    "    model.save('traffic_light_classifier.h5')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd6268ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(file_path, model):\n",
    "\n",
    "    X_test,y_test = pickle.load( open(file_path, \"rb\" ) )\n",
    "\n",
    "    # preprocess data\n",
    "    X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "    print(\"Testing\")\n",
    "\n",
    "    metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "    for metric_i in range(len(model.metrics_names)):\n",
    "        metric_name = model.metrics_names[metric_i]\n",
    "        metric_value = metrics[metric_i]\n",
    "        print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0085d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_an_image(file_path, model):\n",
    "    \"\"\"\n",
    "    resize the input image to [32, 32, 3], then feed it into the NN for prediction\n",
    "    :param file_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    desired_dim=(32,32)\n",
    "    img = cv2.imread(file_path)\n",
    "    img_resized = cv2.resize(img, desired_dim, interpolation=cv2.INTER_LINEAR)\n",
    "    img_ = np.expand_dims(np.array(img_resized), axis=0)\n",
    "\n",
    "#     predicted_state = model.predict_classes(img_)\n",
    "    \n",
    "    predict_x=model.predict(img_) \n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "\n",
    "    return classes_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "864ebeda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 10, 10, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 3204      \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,100\n",
      "Trainable params: 4,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.5333 - accuracy: 0.8253 - val_loss: 0.2775 - val_accuracy: 0.9049\n",
      "Epoch 2/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9129 - val_loss: 0.2253 - val_accuracy: 0.9217\n",
      "Epoch 3/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2194 - accuracy: 0.9237 - val_loss: 0.2015 - val_accuracy: 0.9265\n",
      "Epoch 4/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2054 - accuracy: 0.9291 - val_loss: 0.1908 - val_accuracy: 0.9305\n",
      "Epoch 5/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1953 - accuracy: 0.9357 - val_loss: 0.1830 - val_accuracy: 0.9366\n",
      "Epoch 6/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9377 - val_loss: 0.1806 - val_accuracy: 0.9339\n",
      "Epoch 7/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9349 - val_loss: 0.1781 - val_accuracy: 0.9339\n",
      "Epoch 8/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9396 - val_loss: 0.1747 - val_accuracy: 0.9366\n",
      "Epoch 9/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1792 - accuracy: 0.9397 - val_loss: 0.1716 - val_accuracy: 0.9366\n",
      "Epoch 10/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1763 - accuracy: 0.9411 - val_loss: 0.1714 - val_accuracy: 0.9406\n",
      "Epoch 11/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9401 - val_loss: 0.1698 - val_accuracy: 0.9366\n",
      "Epoch 12/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1715 - accuracy: 0.9428 - val_loss: 0.1713 - val_accuracy: 0.9345\n",
      "Epoch 13/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1680 - accuracy: 0.9419 - val_loss: 0.1788 - val_accuracy: 0.9345\n",
      "Epoch 14/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9435 - val_loss: 0.1738 - val_accuracy: 0.9339\n",
      "Epoch 15/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9426 - val_loss: 0.1691 - val_accuracy: 0.9406\n",
      "Epoch 16/20\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1647 - accuracy: 0.9438 - val_loss: 0.1690 - val_accuracy: 0.9366\n",
      "Epoch 17/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9470 - val_loss: 0.1663 - val_accuracy: 0.9372\n",
      "Epoch 18/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9478 - val_loss: 0.1650 - val_accuracy: 0.9440\n",
      "Epoch 19/20\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1610 - accuracy: 0.9457 - val_loss: 0.1702 - val_accuracy: 0.9413\n",
      "Epoch 20/20\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9480 - val_loss: 0.1661 - val_accuracy: 0.9420\n",
      "Testing\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9369\n",
      "loss: 0.17067325115203857\n",
      "accuracy: 0.9368932247161865\n",
      "green\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = network()\n",
    "    train_file = \"./data/train.p\"\n",
    "    test_file = \"./data/test.p\"\n",
    "\n",
    "    # Train the network\n",
    "    train(train_file, model)\n",
    "\n",
    "    # Test the network\n",
    "    test(test_file, model=load_model('traffic_light_classifier.h5'))\n",
    "\n",
    "    #---Test with a single image---#\n",
    "    demo_flag = True\n",
    "    file_path = './data/green.jpg'\n",
    "    states = ['red', 'yellow', 'green', 'off']\n",
    "    if demo_flag:\n",
    "        predicted_state = test_an_image(file_path, model=load_model('traffic_light_classifier.h5'))\n",
    "        for idx in predicted_state:\n",
    "            print(states[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f87fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d3ea270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e2e6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(states)\n",
    "dff.to_csv('traffic_light_class_names.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56c300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
